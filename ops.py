import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import numpy as np

### Helpers
def _weights(name, shape, mean=0.0, stddev=0.02):
  """ Helper to create an initialized Variable
  Args:
    name: name of the variable
    shape: list of ints
    mean: mean of a Gaussian
    stddev: standard deviation of a Gaussian
  Returns:
    A trainable variable
  """
  var = tf.get_variable(
    name, shape,
    initializer=tf.random_normal_initializer(
      mean=mean, stddev=stddev, dtype=tf.float32))
  return var

def _biases(name, shape, constant=0.0):
  """ Helper to create an initialized Bias with constant
  """
  return tf.get_variable(name, shape,
            initializer=tf.constant_initializer(constant))

def _norm(input, is_training, norm='instance'):
  """ Use Instance Normalization or Batch Normalization or None
  """
  if norm == 'instance':
    return _instance_norm(input)
  elif norm == 'batch':
    return _batch_norm(input, is_training)
  else:
    return input

def _batch_norm(input, is_training):
  """ Batch Normalization
  """
  with tf.variable_scope("batch_norm"):
    return tf.contrib.layers.batch_norm(input,
                                        decay=0.9,
                                        scale=True,
                                        updates_collections=None,
                                        is_training=is_training)

def _instance_norm(input):
  """ Instance Normalization
  """
  with tf.variable_scope("instance_norm"):
    depth = input.get_shape()[3]
    scale = _weights("scale", [depth], mean=1.0)
    offset = _biases("offset", [depth])
    mean, variance = tf.nn.moments(input, axes=[1,2], keep_dims=True)
    epsilon = 1e-5
    inv = tf.rsqrt(variance + epsilon)
    normalized = (input-mean)*inv
    return scale*normalized + offset

def safe_log(x, eps=1e-12):
  return tf.log(x + eps)

def xavier_init(size):
    in_dim = size[0]
    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
    return tf.truncated_normal_initializer(mean=0, stddev=xavier_stddev)

def lrelu(x, slope=0.2): # leaky RELU
    return tf.maximum(slope * x, x)

def plot(real_samples, fake_samples, M):
    """
    # Draw figures for either the real parts or the imaginary parts of the covariance matrix
    real_samples: covariance matrix from the dateset
    fake_samples: covariance matrix generated by the generator
    M: number of antennas
    """
    fig = plt.figure(figsize=(8, 8))
    gs = gridspec.GridSpec(2, real_samples.shape[0])
    gs.update(wspace=0.05, hspace=0.05)

    for i, real in enumerate(real_samples):
        ax = plt.subplot(gs[0,i])
        plt.axis('on')
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_xlabel('Real sample No.%d' % i, fontsize=8)
        ax.set_aspect('equal')
        plt.imshow(real.reshape(M, M), cmap='Greys_r')
    for i, fake in enumerate(fake_samples):
        ax = plt.subplot(gs[1,i])
        plt.axis('on')
        ax.set_xticklabels([])
        ax.set_yticklabels([])
        ax.set_xlabel('Fake sample No.%d' % i, fontsize=8)
        ax.set_aspect('equal')
        plt.imshow(fake.reshape(M, M), cmap='Greys_r')

    return fig

def omni_reshape(y,batch_size,omni_size):
    # Reshape omni-received signal y into size [batch_size, 4, 4, omni_size] for the discriminator
    # Input y size [batch_size, omni_size], not [batch_size, 1,1, omni_size]
    omni_reshaped = np.zeros([1, batch_size * 4 * 4 * omni_size])
    omni_reshaped = np.reshape(omni_reshaped, [batch_size, 4, 4, omni_size])
    for i1 in range(batch_size):
        for j1 in range(4):
            for k1 in range(4):
                omni_reshaped[i1, j1, k1, :] = y[i1, :]
    return  omni_reshaped